{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOPP 2021W Exercise 3\n",
    "## Group 33 - Topic 8 (Endangered Animals)\n",
    "* 01526884 - Sebastian Scholz\n",
    "* 01634043 - Dominik Mailer\n",
    "* 12113875 - Ouassim Kiassa\n",
    "* 11739403 - Thomas Ziller\n",
    "\n",
    "## General Comments\n",
    "The package for plotting interactive diagrams `plotly.express` may need to be installed before the notebook can be run. The library `geopandas` is necessary in order to plot maps.\n",
    "\n",
    "### Work Distribution\n",
    "The work is classified according to the notebook content.\n",
    "\n",
    "#### Dominik, Sebastian\n",
    "* API (IUCN & GBIF) - data gathering (data source search, combination of different data sources), interfaces and providing the data as csv\n",
    "* Basic Data Evaluation\n",
    "* Introduction\n",
    "* Part 1 (General Insights on Endangered Species, Identifying Main Threats, Historical Development, General Geographical Distribution)\n",
    "\n",
    "#### Thomas\n",
    "* Part 2\n",
    "    * API (GBIF) - using interface to fetch data and merge data by latin name\n",
    "    * Implementation of mapping the Coordinates of species occurrences (GBIF) to corresponding climate zone Polygons and processing climate zone data\n",
    "    * Insights on Endangerment distribution and Historical Endangerment across Climate Zone Groups\n",
    "    * Predicting Endangerment for distinct Main Climate Groups and Evaluation of Results\n",
    "\n",
    "#### Ouassim\n",
    "* Part 3\n",
    "    * Countries Data - (Gathering and merging with IUCN), Reshaping and Visualization. \n",
    "    * Predict trends and answering Question 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# all required imports\n",
    "\n",
    "import iucn_data\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import geopandas as pgd \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Point\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from matplotlib.pyplot import figure\n",
    "from prophet import Prophet\n",
    "from prophet.plot import plot_forecast_component, plot_yearly, add_changepoints_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Which dataset(s) did you choose? Why?\n",
    "# How did you clean/transform the data? Why?\n",
    "# How did you solve the problem of missing values? Why?\n",
    "# What questions did you ask of the data?\n",
    "# Why were these good questions?\n",
    "# What were the answers to these questions?\n",
    "# How did you obtain them?\n",
    "# Do the answers make sense?\n",
    "# Were there any difficulties in analysing the data?\n",
    "# What were the key insights obtained?\n",
    "# What are potential biases in the data and analysis?\n",
    "# Which Data Science tools and techniques were learned during this exercise?\n",
    "# How was the work divided up between the members of the group?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "To answer the questions we relied primarily on the International Union for Conservation of Nature's _IUCN Red List of Threatened Species_ [1]. The Red List, founded in 1964, is regarded as the most authoritative and complete list to the conservatory status of species. Using a set of precise criteria it assesses the extinction risk of most species and even subspecies. For each species (or subspecies) a threat level is defined, possible threat levels are:\n",
    "- Least Concern (LC)\n",
    "- Near Threatened (NT)\n",
    "- Vulnerable (VU)\n",
    "- Endangered (EN)\n",
    "- Critically Endangered (CR)\n",
    "- Extinct in the Wild (EW)\n",
    "- Extinct (EX)\n",
    "- additionally: Data Deficient (DD)/Not Evaluated (NE)\n",
    "\n",
    "The IUCN aims to reassess each species at least every 5-10 years. Additionally, to these thread levels information like habitat or threats are published. The data is provided in two ways, either as direct download [2] or as API [3]. Due to the sheer size of the directly downloadable data (multiple Gigabytes due to specific habitat polygons and multiple other, for us, irrelevant fields), and the fact that some species would not be included in this download (e.g. all Birds), we opted to directly use the API. Utilizing the provided API we were able to download only information which we need and thus greatly reduced the size of our raw data. Since the questions are concerned with threatened species, we opted to only include species currently in the categories _CR_ and _EN_.\n",
    "\n",
    "### API description\n",
    "The first step was to query the species of interest (category CR and EN), from the endpoint `/api/v3/species/category/:category`, using this list, and resulting taxon ids the remaining information was taken from the following endpoints: `/api/v3/species/id/:id`, `/api/v3/species/countries/id/:id`, `/api/v3/species/history/id/:id`, `/api/v3/threats/species/id/:id`, `/api/v3/habitats/species`.\n",
    "\n",
    "Aside of the category end-point each of these, required us to traverse our species list and create a single new API-call for each. This constraint resulted in long loading times since a new connection needed to be established for each single call. Our solution was to split the work into multiple batches, so that querying could be stopped and resumed after some time instead of having to wait multiple hours per endpoint. These batches were written into separate csv-files.\n",
    "\n",
    "## Description of *iucn_data*\n",
    "The file `iucn_data.py` contains the logic to read csv-files which were generated using the aforementioned API. Due to size and high response times each query process was done in batches so that work could be paused and resumed, after certain intervals, `icun_data.py` merges these batches (in one instance also two datasets) and ensures that everyone works with the same data-structure. Specifically the following methods are provides: `get_merged_country_info()` for data regarding the distribution area of species, `get_merged_historical_info()` for historical assessments of species, `get_merged_habitat_info()` provides information about the habitat species live in (e.g. Forest or Desert), `get_merged_threats_info()` returns information regaring the current threats, and finally `get_animalia_df()` provides the list of species we consider for this exercise (a more accurat description of each returned dataframe can be found below). For each of these dataframes two fields can be used as keys for operations such as joins or merges, firstly `taxonid_iucn` is an interal, unique ID assigned by the IUCN, secondly the `scientific name` of each species is unique and can also be considered an ID.\n",
    "\n",
    "## Sources\n",
    "[1] <https://www.iucnredlist.org/>\n",
    "[2] <https://www.iucnredlist.org/resources/grid>\n",
    "[3] <http://apiv3.iucnredlist.org/api/v3/docs>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame Description and Data Preparation\n",
    "After the data gathering and column selection we ended up with five dataframes:\n",
    "\n",
    "* *animalia_df*\n",
    "* *historical_df*\n",
    "* *threats_df*\n",
    "* *habitat_df*\n",
    "* *countries_df*\n",
    "\n",
    "*animalia_df* is the main dataframe and the other four have additional information that can be easily combined based on the *taxonid_iucn*.\n",
    "\n",
    "### *animalia_df*\n",
    "Contains all information about the species such as the unique identifier *taxonid_iucn*, but also the scientific name and taxonomic information (e.g. kingdom, phylum, class, etc.).\n",
    "In addition, the threat category (e.g., CR or EN) is also included in this data frame.\n",
    "All other information is not of great interest for answering these questions.\n",
    "All available columns are listed afterwards in the dataframe analysis.\n",
    "\n",
    "### *historical_df*\n",
    "Contains information about the historical assessment of all species from the *animalia_df*.\n",
    "Therefore, in addition to the *taxonid_iucn*, this data frame also contains the year in which a particular assessment was made and the category with the unique category code (e.g. CR or EN).\n",
    "All available columns are listed afterwards in the dataframe analysis.\n",
    "\n",
    "### *threats_df*\n",
    "Contains, for the species (identified by *taxonid_iucn*), all threats that contribute to its vulnerability, e.g. logging and timber harvest, fire, roads and railroads, droughts, etc.\n",
    "Each species can have from 0 to n threats associated with it.\n",
    "All available columns are listed afterwards in the dataframe analysis.\n",
    "\n",
    "### *habitat_df*\n",
    "Contains for the species (identified by *taxonid_iucn*) all habitats where it can possibly occur.\n",
    "Habitat information includes, for example, forests with more specific information such as subtropical or tropical forests, but also wetlands, deserts, coastal areas, etc.\n",
    "Suitability and season information is also provided.\n",
    "Between 0 and n habitats can be assigned to each species.\n",
    "All available columns are listed afterwards in the dataframe analysis.\n",
    "\n",
    "### *countries_df*\n",
    "Primarily contains the information in which countries an animal can occur or was observed in the past.\n",
    "Again, the species can be linked to the country information via the *taxonid_iucn*.\n",
    "For the countries, there is a two-digit and a three-digit code (ISO alpha-2 and ISO alpha-3 codes), the continent, the subregion, and also the occurrence of the animal in that country (e.g., extant or possibly extinct).\n",
    "The original country information we received from IUCN did not include so much country information. Therefore, we enriched it with an additional country-continent file to obtain the ISO alpha-3 country code in addition to the continent and subregion information.\n",
    "Between 0 and n countries can be assigned to each species.\n",
    "All available columns are then listed in the data frame analysis.\n",
    "\n",
    "## Data Quality Checks\n",
    "In the following, some basic data quality checks are performed to determine if data is missing and, if so, what we can do about it.\n",
    "For this purpose, a method plots all columns where values are missing and how many values are missing there.\n",
    "These numbers are visually supported with bar charts to depict the findings.\n",
    "This method is applied to each of the data frames.\n",
    "\n",
    "Additionally, the column data types and some basic data frame information are printed as well for each data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# check for missing values, data types and so on\n",
    "animalia_df = iucn_data.get_animalia_df()\n",
    "historical_df = iucn_data.get_merged_historical_info()\n",
    "threats_df = iucn_data.get_merged_threats_info()\n",
    "habitat_df = iucn_data.get_merged_habitat_info()\n",
    "countries_df = iucn_data.get_merged_country_info()\n",
    "\n",
    "\n",
    "def print_missing_values_summary(df, title, textual_output=False):\n",
    "    nr_missing_values = df.isna().sum()\n",
    "\n",
    "    if textual_output:\n",
    "        print(f\"\\n\\nEvaluation of missing values for {title}:\")\n",
    "        # number of missing values in total\n",
    "        print(nr_missing_values[nr_missing_values > 0])\n",
    "\n",
    "    if nr_missing_values[nr_missing_values > 0].size != 0:\n",
    "        nr_missing_values[nr_missing_values > 0].plot.bar()\n",
    "        plt.xlabel(\"Column\")\n",
    "        plt.ylabel(\"Number of Missing Values\")\n",
    "        plt.title(f\"Missing values (only columns with missing values are given) - {title}\")\n",
    "        plt.gcf().subplots_adjust(bottom=0.4)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f'No missing values for {title}')\n",
    "\n",
    "\n",
    "print(\"\\nAnimal Data - Datatypes/Dataframe-Information:\")\n",
    "print(animalia_df.info())\n",
    "\n",
    "print(\"\\nHistorical Assessment Data - Datatypes/Dataframe-Information:\")\n",
    "print(historical_df.info())\n",
    "\n",
    "print(\"\\nThreats Data - Datatypes/Dataframe-Information:\")\n",
    "print(threats_df.info())\n",
    "\n",
    "print(\"\\nHabitat Data - Datatypes/Dataframe-Information:\")\n",
    "print(habitat_df.info())\n",
    "\n",
    "print(\"\\nCountry Occurrence Data - Datatypes/Dataframe-Information:\")\n",
    "print(countries_df.info())\n",
    "\n",
    "print_missing_values_summary(animalia_df, \"Animal Data\")\n",
    "print_missing_values_summary(historical_df, \"Historical Assessment Data\")\n",
    "print_missing_values_summary(threats_df, \"Threats Data\")\n",
    "print_missing_values_summary(habitat_df, \"Habitat Data\")\n",
    "print_missing_values_summary(countries_df, \"Country Occurrence Data\")\n",
    "\n",
    "species_df = animalia_df.reset_index()\n",
    "country_occurrences_merged = countries_df.reset_index()\n",
    "historical_info_merged = historical_df.reset_index()\n",
    "habitat_info_merged = habitat_df.reset_index()\n",
    "threats_info_merged = threats_df.reset_index()\n",
    "\n",
    "print('\\nChecks what additional information is missing (when merged) for species:')\n",
    "species_without_countries = list(set(species_df['taxonid_iucn'].unique()) - set(country_occurrences_merged['taxonid_iucn'].unique()))\n",
    "print(f'Species without country occurrence: {len(species_without_countries)}')\n",
    "\n",
    "species_without_hist_info = list(set(species_df['taxonid_iucn'].unique()) - set(historical_info_merged['taxonid_iucn'].unique()))\n",
    "print(f'Species without hist info: {len(species_without_hist_info)}')\n",
    "\n",
    "species_without_habitat_info = list(set(species_df['taxonid_iucn'].unique()) - set(habitat_info_merged['taxonid_iucn'].unique()))\n",
    "print(f'Species without habitat info: {len(species_without_habitat_info)}')\n",
    "\n",
    "species_without_threats_info = list(set(species_df['taxonid_iucn'].unique()) - set(threats_info_merged['taxonid_iucn'].unique()))\n",
    "print(f'Species without threats info: {len(species_without_threats_info)}')\n",
    "\n",
    "print('\\nEvaluation on missing codes for Historical Assessment Data:')\n",
    "print(historical_df[historical_df.isnull().any(axis=1)])\n",
    "\n",
    "# Calculating statistical information (mean, std, etc.) is not feasible for these data because they are almost exclusively categorical.\n",
    "# No real outlier handling possible (almost only categorical data).\n",
    "# Missing values could only be corrected manually (not feasible), as we are unable to add habitat or threat information to animals where this information is missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments on Data Quality\n",
    "\n",
    "At first glance, it looks as if many values are already missing in the main dataframe and also in the other dataframes it looks as if many values are missing.\n",
    "However, the missing values only occur in columns that we would not use to answer our questions anyway. Accordingly, these missing values are not a problem.\n",
    "\n",
    "For example, in the *animals_df* we do not use the field *subspecies* or *rank* and also all the other fields are not used by us, because they are partly based on such a deep granularity, which we do not use anyway.\n",
    "\n",
    "Also in the threats dataframe the columns that contain missing values are not needed any further. The same is true for the Habitat information.\n",
    "\n",
    "Only for Historical Assessment Data we are missing 70 codes and this column is also used.\n",
    "However, since the caption is available for these 70 lines and also the year of the assessment, we can see that these values are all from 1965 and also do not directly describe the status \"Endangered\" or \"Critically Endangered\", on which we have put the actual attention.\n",
    "Therefore, these missing values are also negligible.\n",
    "\n",
    "**Lesson Learned**\n",
    "An important lesson learned when checking for missing values and assessing data quality was that, by default, when importing csv files, several strings (with a certain format) are considered as missing values - *nan*.\n",
    "For example, the string \"NA\" (the ISO alpha-2 country code of Namibia) was always displayed as *nan* in the data frame, even though it was present in the file.\n",
    "The solution to this problem was that with the `keep_default_na=False` option and without specifying *na_values*, no strings are parsed as *nan*.\n",
    "\n",
    "### Handling Missing Values and Outliers\n",
    "From the listed data types and by inspecting the files and column names, you can see very quickly that the data we are using here are exclusively categorical values.\n",
    "Therefore, a calculation and description based on descriptive statistics (mean, std, etc.) is not possible and also a meaningful outlier detection is not feasible.\n",
    "There was also no need to clean and transform the data, again largely due to the categorical data.\n",
    "\n",
    "As mentioned earlier, we were able to address the lack of additional country information by integrating an additional file so that we have all the information we need to answer the questions.\n",
    "\n",
    "Missing values for species without country occurrence, habitat information or threat information could only be corrected manually.\n",
    "However, this is not feasible as we are not able to add habitat or threat information to animals where this information is missing because we do not have the necessary expertise (no biologists).\n",
    "\n",
    "### Conclusions on Data Quality\n",
    "In summary, the quality of the data we got through IUCN API calls is really very good and is in fact complete (at least the fields and information we need) and also the codes and other information, for example for countries or endangerment status are consistent and plausible throughout.\n",
    "Also, the *taxonid_iucn* in combination with the scientific name is unique for all entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Question 1/2 - General Insights on Endangered Species\n",
    "* How many species are currently listed as endangered?\n",
    "    * How many animals are endangered in certain continents/areas/countries?\n",
    "    * How many animals are endangered for a certain class (taxonomic rank; e.g., Mammalia)?\n",
    "    * What are the main threats for certain classes?\n",
    "* How has this changed over time?\n",
    "    * How has the number of endangered and critical endangered animals changed over time?\n",
    "\n",
    "In the following, these questions are answered using the data prepared and analyzed above.\n",
    "\n",
    "**Note:** The Pie Charts and some of the Bar Charts are interactive.\n",
    "This means that by clicking on the legend, categories (pie slices or bars) can be hidden and then displayed again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "common_phyla_names = {\n",
    "    'CHORDATA': 'Chordates',\n",
    "    'ARTHROPODA': 'Arthropods',\n",
    "    'MOLLUSCA': 'Mollusks',\n",
    "    'CNIDARIA': 'Cnidarians',\n",
    "    'ANNELIDA': 'Segmented worms',\n",
    "    'ECHINODERMATA': 'Echinoderms',\n",
    "    'ONYCHOPHORA': 'Velvet worms',\n",
    "    'NEMERTINA': 'Ribbon worms'\n",
    "}\n",
    "\n",
    "animalia_df = iucn_data.get_animalia_df()\n",
    "threats_df = iucn_data.get_merged_threats_info()\n",
    "\n",
    "# columns\n",
    "# ['scientific_name', 'subspecies', 'rank', 'subpopulation',\n",
    "#        'threatCategory', 'kingdom', 'phylum', 'class', 'order', 'family',\n",
    "#        'genus', 'main_common_name', 'authority', 'published_year',\n",
    "#        'assessment_date', 'category', 'criteria', 'population_trend',\n",
    "#        'marine_system', 'freshwater_system', 'terrestrial_system', 'assessor',\n",
    "#        'reviewer', 'aoo_km2', 'eoo_km2', 'elevation_upper', 'elevation_lower',\n",
    "#        'depth_upper', 'depth_lower', 'errata_flag', 'errata_reason',\n",
    "#        'amended_flag', 'amended_reason']\n",
    "# print(animalia_df.columns)\n",
    "# print(animalia_df.head(20))\n",
    "\n",
    "# How many species are endangered?\n",
    "count_overall = animalia_df['scientific_name'].nunique()\n",
    "print(f\"There are {count_overall} endangered species in total.\")\n",
    "\n",
    "# critical endangered\n",
    "count_cr = animalia_df[animalia_df['threatCategory'] == 'CR']['scientific_name'].nunique()\n",
    "print(f\"Thereof are {count_cr} critical endangered.\")\n",
    "\n",
    "# endangered\n",
    "count_en = animalia_df[animalia_df['threatCategory'] == 'EN']['scientific_name'].nunique()\n",
    "print(f\"Thereof are {count_en} endangered.\")\n",
    "\n",
    "# PIE CHART\n",
    "# define data\n",
    "df = animalia_df.groupby('threatCategory').size().reset_index(name='counts')\n",
    "\n",
    "labels = ['Critical Endangered', 'Endangered']\n",
    "\n",
    "fig = px.pie(df, values='counts', names=labels,\n",
    "             title='Breakdown of endangered and critical endangered species',\n",
    "             color_discrete_sequence=[\"indianred\", \"darkred\"])\n",
    "fig.show()\n",
    "\n",
    "# BAR CHART with phylum and class\n",
    "df_bar_gen = animalia_df.groupby(['phylum', 'class'])['scientific_name'].count().to_frame()\n",
    "df_bar_gen.sort_values(by=['phylum', 'scientific_name'], ascending=[True, False], inplace=True)\n",
    "df_bar_gen.columns = ['counts']\n",
    "df_bar_gen = df_bar_gen.reset_index()\n",
    "fig = px.bar(df_bar_gen, x='counts', y='class', color='phylum', text_auto='s',\n",
    "             title='Breakdown of endangered (CR and EN) species by Phylum and class',\n",
    "             orientation='h')\n",
    "fig.show()\n",
    "\n",
    "# How many animals are endangered for a certain class (taxonomic rank; e.g., Mammalia)?\n",
    "# by subphylum\n",
    "df = animalia_df.groupby('phylum').size().reset_index(name='counts').sort_values(by=['counts'], ascending=False)\n",
    "df['phylum'] = df['phylum'].map(common_phyla_names)\n",
    "# print(df)\n",
    "\n",
    "fig = px.pie(df, values='counts', names='phylum',\n",
    "             title='Breakdown of endangered (EN and CR) species by Phylum')\n",
    "fig.show()\n",
    "\n",
    "# most interesting Phylum categories: Chordates, Arthropods, Mollusks\n",
    "interesting_cat = ['CHORDATA', 'ARTHROPODA', 'MOLLUSCA']\n",
    "df_red = animalia_df.query('phylum in @interesting_cat')\n",
    "df_red = df_red.groupby(['phylum', 'class'])['scientific_name'].count().to_frame()\n",
    "df_red.sort_values(by=['phylum', 'scientific_name'], ascending=[True, False], inplace=True)\n",
    "df_red.columns = ['counts']\n",
    "# print(df_red)\n",
    "\n",
    "df_bar = df_red.reset_index()\n",
    "fig = px.bar(df_bar, x='counts', y='class', color='phylum', orientation='h',\n",
    "             title='Breakdown - CR and EN species by interesting Phylum and class',\n",
    "             text_auto='s')\n",
    "fig.show()\n",
    "\n",
    "df_p = animalia_df.query('phylum in @interesting_cat').groupby(['phylum', 'class']) \\\n",
    "    .size().reset_index(name='counts') \\\n",
    "    .sort_values(by=['phylum', 'counts'], ascending=[True, False])\n",
    "\n",
    "for cat in interesting_cat:\n",
    "    fig = px.pie(df_p[df_p['phylum'] == cat], values='counts', names=df_p[df_p['phylum'] == cat]['class'].unique(),\n",
    "                 title=f'Number of endangered animals in {cat}')\n",
    "    fig.show()\n",
    "\n",
    "# widely known animal classes are INSECTA, AMPHIBIA, REPTILIA, MAMMALIA, AVES (birds), ACTINOPTERYGII (ray-finned fish, which includes most familiar bony fish)\n",
    "# how much of the total number of endangered animals are one of these classes\n",
    "df_c = animalia_df.groupby(['class', 'threatCategory'])['scientific_name'].count().to_frame()\n",
    "df_c.columns = ['counts']\n",
    "#print(df_c)\n",
    "\n",
    "df_cr_plt = df_c.reset_index()\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 15))\n",
    "sns.barplot(x='counts', y='class', hue='threatCategory', data=df_cr_plt,\n",
    "            palette=[\"darkred\", \"indianred\"],\n",
    "            capsize=0.05,\n",
    "            saturation=8\n",
    "            )\n",
    "ax.legend(ncol=2, loc='lower right')\n",
    "plt.title('Breakdown of endangered species by Class and Threat Category')\n",
    "plt.gcf().subplots_adjust(left=0.25)\n",
    "plt.show()\n",
    "\n",
    "# focus on those with interesting class\n",
    "interesting_classes = ['INSECTA', 'AMPHIBIA', 'REPTILIA', 'MAMMALIA', 'AVES', 'ACTINOPTERYGII']\n",
    "df_c_red = df_c.reset_index().query('`class` in @interesting_classes')\n",
    "df_c_red_ind = df_c_red.set_index(['class', 'threatCategory'])\n",
    "#print(df_c_red_ind)\n",
    "\n",
    "sns.barplot(x='counts', y='class', hue='threatCategory', data=df_c_red,\n",
    "            palette=[\"darkred\", \"indianred\"],\n",
    "            capsize=0.05,\n",
    "            saturation=8\n",
    "            )\n",
    "plt.title('BD of end. species by Class and Threat Category (interesting classes)')\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),\n",
    "      fancybox=True, shadow=True, ncol=5)\n",
    "plt.gcf().subplots_adjust(left=0.25)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "threats = animalia_df.join(threats_df)\n",
    "threats = threats.query('`class` in @interesting_classes')\n",
    "threats = threats[['class', 'title']]\n",
    "threats = threats.groupby(['class', 'title']) \\\n",
    "    .size().reset_index(name='counts') \\\n",
    "    .sort_values(by=['class', 'counts'], ascending=[True, False])\n",
    "print('\\nTop 10 Threats per (interesting) class:')\n",
    "for cls in interesting_classes:\n",
    "    print(threats.query(f'`class` == \"{cls}\"').head(10))\n",
    "\n",
    "\n",
    "## How did it change over time?\n",
    "hist_df = iucn_data.get_merged_historical_info().reset_index()\n",
    "cat = [\"Endangered\", \"Critically Endangered\", \"Vulnerable\"]\n",
    "label_mapping = {\"Critically Endangered\":\"CR\", \"Endangered\":\"EN\", \"Vulnerable\":\"VU\"}\n",
    "cat_cols = [\"indianred\", \"lightblue\", \"darkred\"]\n",
    "df = hist_df.query(f'category in {cat}')\n",
    "\n",
    "df['category'] = df['category'].map(label_mapping)\n",
    "\n",
    "df = df.groupby(['taxonid_iucn', 'category'])['year'].min().reset_index()\n",
    "df = df.groupby(['year', 'category']).count()\n",
    "df.columns = ['counts']\n",
    "\n",
    "df['no_csum'] = df.groupby(['category'])['counts'].cumsum()\n",
    "\n",
    "sns.lineplot(x='year', y='no_csum', hue='category', palette=cat_cols, data=df)\n",
    "plt.title('Historical development of sum of endangered species')\n",
    "plt.show()\n",
    "\n",
    "df_splt = df.reset_index()\n",
    "sns.catplot(\n",
    "    data=df_splt, kind=\"bar\",\n",
    "    x=\"year\", y=\"no_csum\", hue=\"category\", palette=cat_cols, height=6\n",
    ")\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Historical development of sum of endangered species')\n",
    "plt.show()\n",
    "\n",
    "cat_cols = {\n",
    "    \"Lower Risk/least concern\": \"green\",\n",
    "    \"Vulnerable\": \"lightblue\",\n",
    "    \"Endangered\": \"darkred\",\n",
    "    \"Critically Endangered\": \"indianred\"\n",
    "}\n",
    "cat = [\"Lower Risk/least concern\", \"Vulnerable\", \"Endangered\", \"Critically Endangered\"]\n",
    "df = hist_df.query(f'category in {cat}')\n",
    "df = df.groupby(['year', 'category'], as_index=False).size()\n",
    "sns.catplot(data=df, kind=\"bar\",\n",
    "            x='year', y='size', hue='category',\n",
    "            height=6, aspect=3, palette=cat_cols, legend=False,\n",
    "            hue_order=[\"Lower Risk/least concern\", 'Vulnerable', 'Endangered',  \"Critically Endangered\"])\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(loc='center left',)\n",
    "plt.ylabel('Assessments')\n",
    "plt.title('Categorical Assessments in Year')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments on the Results of the First Set of Question\n",
    "In hindsight, the initial questions were quite good, as the answers were quite informative and provided a rough overview of the topic, allowing us to check later findings to see if they were correct.\n",
    "For example, whether the sum of the details matched the numbers we initially received without further differentiation on a more general level.\n",
    "\n",
    "All our analyses and the prepared data focus on the kingdom of animals, according to the [taxonomic ranking](https://en.wikipedia.org/wiki/Taxonomic_rank).\n",
    "Other kingdoms would be plants or fungi.\n",
    "The further classification hierarchy is: Kingdom -> Phylum -> Class -> Order -> Family -> Genus -> Species\n",
    "\n",
    "We started with the total number of endangered and critically endangered animals (kingdom level).\n",
    "Building on this, we went one level down in the hierarchy and looked at the phylum level.\n",
    "There, we looked at the distribution among the respective phylum categories and based on these findings, we selected three main categories: _CHORDATA_, _ARTHROPODA_, _MOLLUSCA_.\n",
    "\n",
    "**CHORDATA**: \"With a cord\" - Hollow dorsal nerve cord, notochord, pharyngeal slits, endostyle, post-anal tail.\n",
    "Pandas, crows, sharks, salamanders, alligators, sea squirts, and many others are examples of chordates\n",
    "Thus, amphibians, reptiles, and mammals are classes that belong to this group.\n",
    "\n",
    "**ARTHROPODA**: \"Jointed foot\" - Segmented bodies and jointed limbs, with Chitin exoskeleton.\n",
    "Lobsters, crabs, spiders, mites, insects, centipedes, and millipedes, for instance, belong to this category.\n",
    "\n",
    "**MOLLUSCA**: \"Soft\" - Muscular foot and mantle round shell.\n",
    "Molluscs include mussels, scallops, oysters, periwinkles, whelks, squid, clams, snails, and octopus.\n",
    "\n",
    "Sources:\n",
    "* <https://en.wikipedia.org/wiki/Phylum>\n",
    "* <https://www.biologyonline.com/dictionary/chordata>\n",
    "* <https://www.britannica.com/animal/arthropod>\n",
    "* <https://www.vedantu.com/biology/mollusca>\n",
    "\n",
    "Based on these findings we again selected promising classes, both known classes and those with many endangered animals.\n",
    "The selection includes *INSECTA* (insects), *AMPHIBIA* (amphibians), *REPTILIA* (reptiles), *MAMMALIA* (mammals), *AVES* (birds), *ACTINOPTERYGII* (ray-finned fish, which includes most familiar bony fish).\n",
    "\n",
    "For all these analyses, both graphs and tabular outputs were produced.\n",
    "\n",
    "In addition, the main threats were also listed for species classes of interest.\n",
    "For each class, the top 10 threats were listed.\n",
    "The number indicates how often this hazard was indicated as being endangering to this class.\n",
    "\n",
    "Then we also looked at how the number of endangered animals has developed and changed (worsened) over the years.\n",
    "For this purpose, we used the information from the historical assessments.\n",
    "For each animal in combination with the threat status, we took the smallest year in which the status appeared for the first time and then calculated a cumulative sum per year.\n",
    "Thus, one can see how the numbers have increased over time.\n",
    "Downgrades in endangerment status almost did not take place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fix_missing_codes(world):\n",
    "    # just done because of an existing bug - https://github.com/geopandas/geopandas/issues/1041\n",
    "    world2 = world.copy()\n",
    "    world2.loc[world['name'] == 'France', 'iso_a3'] = 'FRA'\n",
    "    world2.loc[world['name'] == 'Norway', 'iso_a3'] = 'NOR'\n",
    "    world2.loc[world['name'] == 'Somaliland', 'iso_a3'] = 'SOM'\n",
    "    world2.loc[world['name'] == 'Kosovo', 'iso_a3'] = 'RKS'\n",
    "    return world2\n",
    "\n",
    "\n",
    "def df_to_plot(df_map, column_to_map, title):\n",
    "    ax = df_map.plot(column=column_to_map, cmap='OrRd', legend=True, figsize=(10,8),\n",
    "                     legend_kwds={'label': 'number of species (CR & EN),', 'orientation': \"horizontal\"},\n",
    "                     missing_kwds={'color': 'lightgrey'})\n",
    "    ax.set_axis_off()\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "world = pgd.read_file(pgd.datasets.get_path('naturalearth_lowres'))\n",
    "world = fix_missing_codes(world)\n",
    "world_min = world[['iso_a3', 'continent', 'geometry']]\n",
    "animalia_df = iucn_data.get_animalia_df()\n",
    "country_df = iucn_data.get_merged_country_info()\n",
    "\n",
    "df = animalia_df.join(country_df, how='left')\n",
    "df = df.drop('continent', axis=1)\n",
    "df = df.merge(world_min, left_on='code_3', right_on='iso_a3', how='right')\n",
    "\n",
    "\n",
    "# only phylum - continent\n",
    "phylum = ['CHORDATA', 'ARTHROPODA', 'MOLLUSCA']\n",
    "df_p = df.query('phylum in @phylum')\n",
    "\n",
    "# plot per continent\n",
    "continent_count = df_p.groupby(['continent'], as_index=False).size()\n",
    "df_2 = world_min.merge(continent_count)\n",
    "df_to_plot(df_2, 'size', f'Species by Continent\\n ({\", \".join(phylum)})')\n",
    "\n",
    "# plot per country\n",
    "country_count = df.groupby(['iso_a3'], as_index=False).size()\n",
    "df_2 = world_min.merge(country_count, how='left')\n",
    "df_to_plot(df_2, 'size', f'Species by Country\\n ({\", \".join(phylum)})')\n",
    "\n",
    "interesting_classes = ['INSECTA', 'AMPHIBIA', 'REPTILIA', 'MAMMALIA', 'AVES', 'ACTINOPTERYGII']\n",
    "df_c = df.query('`class` in @interesting_classes')\n",
    "country_count = df_c.groupby(['iso_a3'], as_index=False).size()\n",
    "df_2 = world_min.merge(country_count, how='left')\n",
    "df_to_plot(df_2, 'size', f'Species by Country\\n ({\", \".join(interesting_classes)})')\n",
    "\n",
    "for cla in interesting_classes:\n",
    "    df_ci = df.query('`class` == @cla')\n",
    "    country_count = df_ci.groupby(['iso_a3'], as_index=False).size()\n",
    "    df_2 = world_min.merge(country_count, how='left')\n",
    "    df_to_plot(df_2, 'size', f'Species by Country\\n ({cla})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments on the Results of Geographical Distribution\n",
    "\n",
    "The same categories, phylums and classes as above have been plotted with regard to their geographical distribution.\n",
    "\n",
    "### Overview per Phylum\n",
    "The first two graphics shows a very broad summary, plotted are _Endangered_ and _Critically Endangered_ species of the phylum(s): _Chordata_, _Arthropoda_ and _Mollusca_.\n",
    "\n",
    "#### Continental Overview\n",
    "For each continent the sum of species fitting these criteria was calculated and plotted.\n",
    "One can see a clear distinctions between continental trends, with Asia and Africa having the most species classified as endangered.\n",
    "\n",
    "#### Overview per Country\n",
    "A more detailed look is given in the second graphic where for each country the sum of endangered species is calculated separately. In comparison to the above here a stark difference between individual countries can be seen, for example in Asia where Indonesia, despite being smaller, doubles the number of most other countries.\n",
    "\n",
    "### Overview per Class\n",
    "The other maps depict the distribution of each single class: _Insecta_, _Amphibia_, _Reptilia_, _Mammalia_, _Aves_ and _Actinopterygii_ (see above for explanations). For most (e.g. Amphibia and Reptilia) a direct trend towards the equatorial regions can be seen.\n",
    "\n",
    "## General Trends\n",
    "Especially the class/country overview shows a direct trend towards equatorial regions (Reptilia and Aves), in these regions one can again see a clear distinction between tropical countries and countries which have a drier climate.\n",
    "These trends are to be expected since, biodiversity in hot, tropical regions is generally much higher, and thus the absolut number of species, some of them very specialised for a specific ecological niche, is much higher. With this higher specialisation also comes a higher vulnerability to common threats such as loss of suitable habitats.\n",
    "\n",
    "### Outliers and Lessons learned\n",
    "Outlier (in the form of, missing or unbelievable data) can have multiple causes. Data was not yet collected or assessed, which is not very believable for countries in Europe (e.g. for Amphibia), or, since only CR and EN are considered, the species that were at risk are already largely extinct in the respective countries. However, due to the sheer number of such, negative, outliers it is to believed that either the raw data is missing/incomplete or that mapping to the library used for drawing the maps is faulty.\n",
    "\n",
    "Geographical data, the data provided by the library _geopandas_ seems to have multiple bugs and issues regarding specific countries [1], while some of these were resolved it could be that some are still undetected. Overall mapping to countries is no trivial task, multiple sources of errors, from naming conventions to political debates (i.e. China and Taiwan) to the specific granularity (e.g. Hawaii or USA) can cause issues when mapping data to a geographical representation (based on political territories such as countries). A more robust approach would have been to use geographical data in the form of polygons and lat/lang pairs, however we decided against this approach due to the sheer size of the data necessary.\n",
    "\n",
    "Another lesson is that the information is not as useful as initially thought. Since only the sum of species is used, large countries, with more overall species, naturally tend to also have more that are endangered. A better approach would have been to use the fraction of endangered species of a country (e.g. 10 out of 500), which would have made comparison more meaningful. However, despite this 'advantage' some smaller countries, like Indonesia, still outranked large countries. This is most likely due to their more at risk geological position and very high biodiversity.\n",
    "\n",
    "[1] <https://github.com/geopandas/geopandas/issues/1041>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3a/4a - Additional Insights on Endangerment based on Geographical and Natural Characteristics \n",
    "* Which geographical and natural characteristics predict higher numbers of endangered\n",
    "species?\n",
    "    * How has endangerment developed across climate zones?\n",
    "    * What climate zone characteristics predict higher numbers of endangered species?\n",
    "    * Can these characteristics predict trends in the number of species?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional data\n",
    "As the spatial data provided by the IUCN was not appropriate for our use-case due to computational restrictions (multiple GB of data), we enriched our dataset with data provided by the GBIF API. The interface we implemented for fetching the data can be observed in 'data_fetching/gbif_api.py'. Luckily, both APIs (ICUN and GBIF), both provide a common identifier attribute - the species' latin name. However, we faced a few issues during the process of data gathering. On the one hand, the implementation of latin names were not as consistent as we wish it was. For example, species names in GBIF data occassionally had additional attributes listed along the string such as the year of the species' discovery. Additionally, not all species listed in the IUCN data are present in the GBIF data. However, we still decided to keep going with this approach due to lack of other feasible options and we ended up with 2753 out of 9958 records left for further analysis.\n",
    "\n",
    "From the beginning of our work, we immediatly were curious in the distribution of endangerment across climate zones as media reporting of the mass extinction happening especially in the South American rainforest has accompanied us ever since our youth. To be able to incorporate climate zone characteristics into our analysis, we decided to use the broadly established Köppen-Geiger classification.  As decribed in the already presented Workplan, we decided to use geographical data provided by the IGRAC (International Groundwater Resources Assessment Centre) as it would ultimately allow us to combine it with the coordinates retrieved by the GBIF API to match each species into one corresponding climate zone. Out of the 2753 remaining records, we were able to do so for over 80 % of records ending up with around 2255 properly matched species. Furthermore, as mapping each and every recorded animal occurrence of the last decades to its corresponding climate zone would vastly exceed our computational capacity, we decided to heuristically consider the latest entry provided as the species' current location. This may lead to minor misclassifications, however, especially considering the five main groups, we determined eventual biases as negligible, again, also due to lack of other options. We also thought about using median or mean coordinates but this might cause other irritations such as eventually coming up with originally non-existent species locations due to the two-pieced nature of coordinates.\n",
    "\n",
    "As already described in the previous sections, the IUCN animal data does include missing values. However, as these attributes will not be considered for the upcoming part, no further description will be implemented. Regarding outliers, we are still dealing with categorical data only so no need for further mention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load climate zone data and convert geometry\n",
    "zone_df = pd.read_csv(\"./data/climate_zone/koppen_geiger_climate_zones.csv\")\n",
    "zone_df['geometry'] = zone_df['geometry'].apply(wkt.loads)\n",
    "zone_df[\"climate\"] = zone_df[\"climate\"].str.replace('_',' ')\n",
    "# Load fresh animalia data \n",
    "animalia = iucn_data.get_animalia_df()\n",
    "# Load species location\n",
    "location = pd.read_csv(\"./data/climate_zone/species_location.csv\", index_col=0)\n",
    "# Merge animalia dataframe with species location dataframe\n",
    "animalia_loc = pd.merge(animalia.reset_index(), location, how=\"outer\")\n",
    "\n",
    "# Map species observation to climate zone using the Shapely module \n",
    "def map_coordinates(data, zone_df):\n",
    "    \n",
    "    climate_series = []\n",
    "    polygon = []\n",
    "\n",
    "    for j, point in data.iterrows():\n",
    "        for i, zone in zone_df.iterrows():\n",
    "            if Point(data.iloc[j][\"decimalLongitude\"], data.iloc[j][\"decimalLatitude\"]).within(zone_df.iloc[i][\"geometry\"]):\n",
    "                climate_series.append(zone_df.iloc[i][\"climate\"])\n",
    "                polygon.append(zone_df.iloc[i][\"geometry\"])\n",
    "        if len(climate_series) == j:\n",
    "            climate_series.append(float(\"nan\"))\n",
    "            polygon.append(float(\"nan\"))\n",
    "\n",
    "    return climate_series, polygon\n",
    "\n",
    "climate_animalia = animalia_loc[(animalia_loc.decimalLatitude.notnull()) & (animalia_loc[\"decimalLatitude\"]!=0)]\n",
    "climate_animalia[\"climate\"], climate_animalia[\"geometry\"] = map_coordinates(climate_animalia.reset_index(drop=True), zone_df)\n",
    "\n",
    "\n",
    "# Tidy Collection of more granular aspects of climate zones for splitting climate zone into different groups\n",
    "main_groups = {\"A\": \"A (Tropical)\", \n",
    "               \"B\": \"B (Arid)\", \n",
    "               \"C\": \"C (Temperate)\", \n",
    "               \"D\": \"D (Continental)\", \n",
    "               \"E\": \"E (Polar)\"}\n",
    "\n",
    "seasonal_temperature_groups = {\"A\": {\"f\": \"f (Rainforest)\",\n",
    "                                    \"m\": \"m (Monsoon)\",\n",
    "                                    \"w\": \"w (Savanna, Dry winter)\",\n",
    "                                    \"s\": \"s (Savanna, Dry summer)\"},\n",
    "                               \"B\": {\"W\": \"W (Desert)\",\n",
    "                                     \"S\": \"S (Steppe)\"},\n",
    "                               \"C\": {\"w\": \"w (Dry winter)\",\n",
    "                                     \"f\": \"f (No dry season)\",\n",
    "                                     \"s\": \"s (Dry summer)\"},\n",
    "                               \"D\": {\"w\": \"w (Dry winter)\",\n",
    "                                     \"f\": \"f (No dry season)\",\n",
    "                                     \"s\": \"s (Dry summer)\"},\n",
    "                               \"E\": {\"T\": \"T (Tundra)\",\n",
    "                                    \"F\": \"Eternal frost(ice cap))\"}\n",
    "                              }\n",
    "\n",
    "heat_groups = {\"B\": {\"h\": \"h (Hot)\",\n",
    "                      \"k\": \"k (Cold)\"},\n",
    "              \"C\": {\"a\": \"a (Hot summer)\",\n",
    "                   \"b\": \"b (Warm summer)\",\n",
    "                   \"c\": \"c (Cold summer)\"},\n",
    "              \"D\": {\"a\": \"a (Hot summer)\",\n",
    "                   \"b\": \"b (Warm summer)\",\n",
    "                   \"c\": \"c (Cold summer)\",\n",
    "                   \"d\": \"d (Very cold winter)\"}}\n",
    "                               \n",
    "\n",
    "# Map 1st, 2nd and 3rd climate zone group based on column 'climate' \n",
    "# Add groups as columns to enable analysis\n",
    "def encode_cz(data, mg, stg, hg):\n",
    "\n",
    "      for index, group_entry in data[\"climate\"].iteritems():\n",
    "            if  group_entry:\n",
    "                  data.loc[index, \"main group\"] = mg[group_entry[0]]\n",
    "                  data.loc[index, \"seasonal precipitation group\"] = stg[group_entry[0]][group_entry[1]]\n",
    "\n",
    "                  if len(group_entry.split(\" \")[0]) == 3:\n",
    "                        data.loc[index, \"heat group\"] = hg[group_entry[0]][group_entry[2]]\n",
    "                  else: data.loc[index, \"heat group\"] = np.nan\n",
    "      \n",
    "      return data\n",
    "\n",
    "df_animalia_climate = encode_cz(climate_animalia[climate_animalia[\"climate\"].notna()], main_groups, seasonal_temperature_groups, heat_groups)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Köppen-Geiger Climate Classification\n",
    "\n",
    "The Köppen-Geiger Climate classification is widely used to dissect our world into regions with increasing granularity (level 1-3). The first letter of the declaration indicates the *main group*, namingly:\n",
    "- Group A: Tropical Climates\n",
    "- Group B: Dry Climates\n",
    "- Group C: Temperate Climates\n",
    "- Group D: Continental Climates\n",
    "- Group E: Polar and Alpine Climates\n",
    "\n",
    "Within each of these groups, we can find up to 12 different subtypes as the second letter indicates the seasonal precipitation subgroup while the third letter (e.g., Cfb) declares the heat subgroup. In general, these groups are defined by their average temperature, seasons occuring over the year as well as precipitation. Interestingly, the main groups were distinguished by the type of vegetation present in the area.\n",
    "\n",
    "Needless to say, treating each present subtype is out of the scope of this project, especially as the main groups already provide us with valuable characteristics which allow further processing. Furthermore, we think these characteristics may be interpreted both as geographical as well as natural characteristics as the by definition, the zone tells us about the local geography and gives us also an impression of the species habitat.\n",
    "\n",
    "##### Sources\n",
    "* <https://en.wikipedia.org/wiki/K%C3%B6ppen_climate_classification>\n",
    "* <https://www.gbif.org/>\n",
    "\n",
    "### Comments on Exploratory Analysis\n",
    "\n",
    "Taking a look at animal occurrences on the world map, one can instantly recognize that most species are located in the tropical and temperated region of our planet. Even though these records only take endangered animals into account, this also reensembles our own domain knowledge of animals. In total, over 50% of endangered species have been recorded in the tropics, however, also temperated regions such as most of Europe or the eastern side of the United States are affected by heavy extinction. Taking into account the characteristics of these two groups, we can derive that mild to hot temperatures with sufficient precipitation and humidity are the center of current mass extinction.\n",
    "Transforming the data into a time series confirmed this assumption as even though endangerment  has increased across all groups, Tropical and Temperate are leading the race with consistently increasing numbers. However, one must note that these are absolute numbers only. Considering relative changes, one might find even more drastically patterns in other Area's such as certan subtypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot climate zones\n",
    "zone_df[\"main group\"] = zone_df[\"climate\"].astype(str).str[0]\n",
    "zone_df[\"main group\"] = zone_df[\"main group\"].map(main_groups)\n",
    "df_animalia_climate = df_animalia_climate.apply(pd.to_numeric, errors='ignore')\n",
    "df_animalia_climate[\"observation point\"] = df_animalia_climate.apply(lambda r: Point(r[\"decimalLongitude\"],r[\"decimalLatitude\"]), axis=1) \n",
    "\n",
    "gdf = pgd.GeoDataFrame(zone_df)\n",
    "fig, gax = plt.subplots(figsize=(10,10))\n",
    "gdf.plot(ax=gax, column=\"main group\", edgecolor=\"black\",  legend=True)\n",
    "\n",
    "gax.set_xlabel('longitude')\n",
    "gax.set_ylabel('latitude')\n",
    "gax.set_title(\"Species Occurrences on Main Climate Groups\")\n",
    "gax.spines['top'].set_visible(False)\n",
    "gax.spines['right'].set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "# Plot occurrences\n",
    "fig, gax = plt.subplots(figsize=(10,10))\n",
    "gdf.plot(ax=gax, column=\"main group\", edgecolor=\"black\",  legend=True)\n",
    "df_animalia_climate[[\"taxonid_iucn\", \"decimalLongitude\", \"decimalLatitude\", \"observation point\"]].plot(ax=gax, marker='o', \n",
    "                                                    x=\"decimalLongitude\", y=\"decimalLatitude\", kind=\"scatter\", color='red', alpha=0.2)\n",
    "gax.set_xlabel('longitude')\n",
    "gax.set_ylabel('latitude')\n",
    "gax.set_title(\"Species Occurrences on Main Climate Groups\")\n",
    "gax.spines['top'].set_visible(False)\n",
    "gax.spines['right'].set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "# Plot relative distribution of endangerment across main groups \n",
    "end_by_mg = df_animalia_climate.pivot_table(index=[\"main group\"], columns=\"threatCategory\", aggfunc=\"size\", fill_value=0).reset_index()\n",
    "fig = px.pie(end_by_mg,width=500,height=500,  values='EN', names='main group',\n",
    "             title='Breakdown of Endangerment by Main Climate Group')\n",
    "fig.show()\n",
    "\n",
    "# Plot relative distribution of endangerment across subgroup precipitation of group Tropical \n",
    "df_tropical = df_animalia_climate[df_animalia_climate[\"main group\"] == \"A (Tropical)\"]\n",
    "trop_end_by_spg = df_tropical.pivot_table(index=[\"seasonal precipitation group\"], columns=\"threatCategory\", aggfunc=\"size\", fill_value=0).reset_index()\n",
    "fig = px.pie( trop_end_by_spg, width=500,height=500,values='EN', names='seasonal precipitation group',\n",
    "             title='Breakdown of Critical Endangerment by Seasonal Precipitation Group in Tropical Area')\n",
    "fig.show()\n",
    "\n",
    "# Plot relative distribution of endangerment across subgroup precipitation of group Temperate \n",
    "df_tropical = df_animalia_climate[df_animalia_climate[\"main group\"] == \"C (Temperate)\"]\n",
    "trop_end_by_spg = df_tropical.pivot_table(index=[\"seasonal precipitation group\"], columns=\"threatCategory\", aggfunc=\"size\", fill_value=0).reset_index()\n",
    "fig = px.pie( trop_end_by_spg, width=500,height=500,values='EN', names='seasonal precipitation group',\n",
    "             title='Breakdown of Critical Endangerment by Seasonal Precipitation Group in Temperate Area')\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# Process data for time series (group by year and main group with count, unstack, alter index structure as MultiIndex causes problems, front-fill value for non-existent years, cumulating records over time)\n",
    "df_climate_hist = pd.merge(hist_df[(hist_df[\"code\"]==\"EN\") |  (hist_df[\"code\"]==\"CR\")], df_animalia_climate, on=\"taxonid_iucn\")\n",
    "df_climate_hist = df_climate_hist[[\"taxonid_iucn\", \"year\", \"main group\"]]\n",
    "df_climate_hist_time = df_climate_hist.groupby(['year','main group']).count()\n",
    "df_climate_hist_time = df_climate_hist_time.unstack('year', fill_value='').T.replace('', np.nan).ffill()\n",
    "df_climate_hist_time.index = df_climate_hist_time.index.droplevel(0)\n",
    "df_climate_hist_time = df_climate_hist_time.cumsum()\n",
    "df_climate_hist_time = df_climate_hist_time.reset_index()\n",
    "\n",
    "# Plot time series with main group as category\n",
    "cat_cols = {\n",
    "    \"A (Tropical)\": \"green\",\n",
    "    \"B (Arid)\": \"darkred\",\n",
    "    \"C (Temperate)\": \"lightblue\",\n",
    "    \"D (Continental)\": \"indianred\",\n",
    "    \"E (Polar)\": \"steelblue\"\n",
    "}\n",
    "\n",
    "ax = df_climate_hist_time.plot.bar(x='year', figsize=(14, 1.5), color=cat_cols, \n",
    "                    ylabel=\"Assessment\", title=\"Categorical Assessment by Climate Main Group in Year\")\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig(\"../../../categorical_assessment.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments on Climate Zone Prediction\n",
    "\n",
    "After performing additional transformation steps such as grouping, unstacking and transposing the data to create proper format for forecasting, the final results showed that within a marginal range of a few percentage points, we can forecast the number of expected species to be endangered for each of the five main groups for single years. However, key for this prediction is the historical data which allows us to extrapolate into the future. For this particular case, we decided to rely on a classic linear regression model due to several reasons:\n",
    "- The data missed passing stability tests necessary for ARIMA-models\n",
    "- There is no cyclical pattern\n",
    "- The data movement over time appeared rather simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Polar as too few values for modeling\n",
    "df_climate_hist_time = df_climate_hist_time.drop(columns=\"E (Polar)\")\n",
    "# Split data randomly across years for train-test-split\n",
    "test = df_climate_hist_time.sample(math.floor(len(df_climate_hist_time)/5))\n",
    "train = df_climate_hist_time.drop(test.index.values, axis=0)\n",
    "\n",
    "# Train one linear model for each main group \n",
    "y_col = [x for x in test.columns if not x.startswith(\"year\")]\n",
    "\n",
    "for col in y_col:\n",
    "    lm_t = LinearRegression().fit(train.index.values.reshape(-1, 1), train[col])\n",
    "    test[col + \" Estimate\"] = lm_t.predict(test.index.values.reshape(-1,1))\n",
    "\n",
    "# Compute %-error \n",
    "def calc_relative_error(data):\n",
    "    for col in data.columns[1:5]:\n",
    "        data[col + \" relative Error\"] = abs(1 - data[col] / data[col+\" Estimate\"])\n",
    "    return data\n",
    "\n",
    "# Print test set, compute mean of relative error, plot results\n",
    "test.head()\n",
    "test_rel = calc_relative_error(test)\n",
    "print(test_rel.mean())\n",
    "test.plot(kind=\"scatter\", x=\"year\", y=y_col, backend=\"plotly\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learnings of Question 3a/4a\n",
    "- Working with Geo-Data is challenging, however, there are great implementations such as GeoPandas and Shapely\n",
    "- Computational restraints seem to be a serious issue when processing Geo-Data\n",
    "- The incorporation of diverse data sources creates opportunities for great insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3b - Country characteristics\n",
    "\n",
    "* Which geographical and natural characteristics predict higher numbers of endangered\n",
    "species?\n",
    "\n",
    "## Additional DataFrame Description and Data Preparation\n",
    "\n",
    "* *CO2*\n",
    "* *FOREST*\n",
    "* *POPULATION*\n",
    "* *METHAN EMISSIONs*\n",
    "* *RENEWABLE ENERGY*\n",
    "\n",
    "### *CO2*\n",
    "\n",
    " \"CO2 emissions (kt)\",\"Carbon dioxide emissions are those stemming from the burning of fossil fuels and the manufacture of cement. They include carbon dioxide produced during consumption of solid, liquid, and gas fuels and gas flaring.\"\n",
    "\n",
    "### *FOREST*\n",
    "\n",
    " \"Forest area (% of land area)\",\"Forest area is land under natural or planted stands of trees of at least 5 meters in situ, whether productive or not, and excludes tree stands in agricultural production systems (for example, in fruit plantations and agroforestry systems) and trees in urban parks and gardens.\"\n",
    "\n",
    " ### *POPULATION*\n",
    "\n",
    "  \"Population growth (annual %)\",\"Annual population growth rate for year t is the exponential rate of growth of midyear population from year t-1 to t, expressed as a percentage . Population is based on the de facto definition of population, which counts all residents regardless of legal status or citizenship.\",\"Derived from total population.\"\n",
    "\n",
    "### *METHAN EMISSIONs*\n",
    "\n",
    "\"Methane emissions (kt of CO2 equivalent)\",\"Methane emissions are those stemming from human activities such as agriculture and from industrial methane production.\"\n",
    "\n",
    "### *RENEWABLE ENERGY*\n",
    "\n",
    "\"Renewable energy consumption (% of total final energy consumption)\",\"Renewable energy consumption is the share of renewables energy in total final energy consumption.\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Source\n",
    "\n",
    "*  <https://data.worldbank.org/indicator>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_df = iucn_data.get_merged_historical_info()\n",
    "threats_df = iucn_data.get_merged_threats_info()\n",
    "habitat_df = iucn_data.get_merged_habitat_info()\n",
    "animalia_df = iucn_data.get_animalia_df()\n",
    "country_df = iucn_data.get_merged_country_info()\n",
    "\n",
    "country_co2_raw = pd.read_csv(\"./data/country/CO2/API_EN.ATM.CO2E.KT_DS2_en_csv_v2_3470002.csv\", quotechar = '\"', skiprows=4)\n",
    "country_fst_raw = pd.read_csv(\"./data/country/Forest/API_AG.LND.FRST.ZS_DS2_en_csv_v2_3469441.csv\", quotechar = '\"', skiprows=4)\n",
    "country_pop_raw = pd.read_csv(\"./data/country/Population/API_SP.POP.GROW_DS2_en_csv_v2_3469469.csv\", quotechar = '\"', skiprows=4)\n",
    "country_me_raw = pd.read_csv(\"./data/country/methan/API_EN.ATM.METH.KT.CE_DS2_en_csv_v2_3471999.csv\", quotechar = '\"', skiprows=4)\n",
    "country_re_raw = pd.read_csv(\"./data/country/RE/API_EG.FEC.RNEW.ZS_DS2_en_csv_v2_3471475.csv\", quotechar = '\"', skiprows=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_co2_raw = country_co2_raw.rename(columns={\"Country Name\": \"Country\"})\n",
    "country_fst_raw = country_fst_raw.rename(columns={\"Country Name\": \"Country\"})\n",
    "country_pop_raw = country_pop_raw.rename(columns={\"Country Name\": \"Country\"})\n",
    "country_me_raw = country_me_raw.rename(columns={\"Country Name\": \"Country\"})\n",
    "country_re_raw = country_re_raw.rename(columns={\"Country Name\": \"Country\"})\n",
    "\n",
    "country_co2 = country_co2_raw.set_index(\"Country\")\n",
    "country_fst = country_fst_raw.set_index(\"Country\")\n",
    "country_pop = country_pop_raw.set_index(\"Country\")\n",
    "country_me = country_me_raw.set_index(\"Country\")\n",
    "country_re = country_re_raw.set_index(\"Country\")\n",
    "\n",
    "country_co2_t = country_co2.drop(['Indicator Code', 'Indicator Name', 'Country Code'], axis=1)\n",
    "country_fst_t = country_fst.drop(['Indicator Code', 'Indicator Name', 'Country Code'], axis=1)\n",
    "country_pop_t = country_pop.drop(['Indicator Code', 'Indicator Name', 'Country Code'], axis=1)\n",
    "country_me_t = country_me.drop(['Indicator Code', 'Indicator Name', 'Country Code'], axis=1)\n",
    "country_re_t = country_re.drop(['Indicator Code', 'Indicator Name', 'Country Code'], axis=1)\n",
    "\n",
    "country_co2_t = country_co2_t.T\n",
    "country_fst_t = country_fst_t.T\n",
    "country_pop_t = country_pop_t.T\n",
    "country_me_t = country_me_t.T\n",
    "country_re_t = country_re_t.T\n",
    "\n",
    "selected_countries_co2 = country_co2_t[[\"India\", \"United States\", \"Mexico\", \"Russian Federation\", \"Vietnam\", \"Thailand\"]].T\n",
    "selected_countries_forest = country_fst_t[[\"India\", \"United States\", \"Mexico\", \"Russian Federation\", \"Vietnam\", \"Thailand\"]].T\n",
    "selected_countries_pop = country_pop_t[[\"India\", \"United States\", \"Mexico\", \"Russian Federation\", \"Vietnam\", \"Thailand\"]].T\n",
    "selected_countries_me = country_me_t[[\"India\", \"United States\", \"Mexico\", \"Russian Federation\", \"Vietnam\", \"Thailand\"]].T\n",
    "selected_countries_re = country_re_t[[\"India\", \"United States\", \"Mexico\", \"Russian Federation\", \"Vietnam\", \"Thailand\"]].T\n",
    "\n",
    "\n",
    "co2 = country_co2_t[[\"Russian Federation\", \"Vietnam\", \"Thailand\", \"United States\", \"Mexico\", \"India\"]]\n",
    "pop = country_pop_t[[\"Russian Federation\", \"Vietnam\", \"Thailand\", \"United States\", \"Mexico\", \"India\"]]\n",
    "forest = country_fst_t[[\"Russian Federation\", \"Vietnam\", \"Thailand\", \"United States\", \"Mexico\", \"India\"]]\n",
    "me = country_me_t[[\"Russian Federation\", \"Vietnam\", \"Thailand\", \"United States\", \"Mexico\", \"India\"]]\n",
    "re = country_re_t[[\"Russian Federation\", \"Vietnam\", \"Thailand\", \"United States\", \"Mexico\", \"India\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_missing_values_summary(df, title):\n",
    "    print(f\"\\n\\nEvaluation of missing values for {title}:\")\n",
    "    # number of missing values in total\n",
    "    nr_missing_values = df.isna().sum()\n",
    "    print(nr_missing_values[nr_missing_values > 0])\n",
    "\n",
    "    if nr_missing_values[nr_missing_values > 0].size != 0:\n",
    "        nr_missing_values[nr_missing_values > 0].plot.bar(figsize=(20,10))\n",
    "        plt.xlabel(\"Column\")\n",
    "        plt.ylabel(\"Number of Missing Values\")\n",
    "        plt.title(f\"Missing values for all columns - {title}\")\n",
    "        plt.gcf().subplots_adjust\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f'No missing values for {title}')\n",
    "\n",
    "print(\"\\nA - Datatypes/Dataframe-Information:\")\n",
    "print(country_co2_raw.info())\n",
    "\n",
    "print(\"\\nB - Datatypes/Dataframe-Information:\")\n",
    "print(country_fst_raw.info())\n",
    "\n",
    "print(\"\\nB - Datatypes/Dataframe-Information:\")\n",
    "print(country_pop_raw.info())\n",
    "\n",
    "\n",
    "\n",
    "print_missing_values_summary(country_co2_raw, \"Missing Values of Co2 Dataset\")\n",
    "print_missing_values_summary(country_fst_raw, \"Missing Values of Forest Dataset\")\n",
    "print_missing_values_summary(country_pop_raw, \"Missing Values of Population Dataset\")\n",
    "print_missing_values_summary(country_me_raw, \"Missing Values of Methan Dataset\")\n",
    "print_missing_values_summary(country_re_raw, \"Missing Values of Renewable Energy Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values and Outliers\n",
    "\n",
    "From the first observations in the plots, we can quickly notice a whole range of missing values specifically from 1960 to 1990, which makes sense because this data contains more than 160* countries, and not every country tracks this kind of data.\n",
    "however, all missing values related to these countries are removed because of the redundant  data and we cannot make any use of it (i.e., countries that have data from 1970 to 1975 then they have another data from 2000 t0 2005), also because we use the library \"PROPHET\" that predict future forecasts, it can't handle missing data, therefore, the dropping of this data was necessary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_piechart_sum(df, title, value):\n",
    "    Temp = df.reset_index()\n",
    "    varr = Temp.sum(axis = 1)\n",
    "    Temp[f\"{value}\"] = varr\n",
    "    fig1 = px.pie(Temp,\n",
    "                                    values=f\"{value}\", \n",
    "                                    names='Country',\n",
    "                                    title=f'{title}')\n",
    "    fig1.show()\n",
    "\n",
    "def print_lineplot_sum(df, title, ylabel):\n",
    "    df.plot(figsize=(20,5))\n",
    "    plt.xlabel('Years')\n",
    "    plt.ylabel(f'{ylabel}') \n",
    "    plt.title(f'{title}')\n",
    "    plt.show()\n",
    "\n",
    "def print_barplot_sum(df, title, ylabel):\n",
    "    ssc = df[[\"Russian Federation\", \"Vietnam\", \"Thailand\", \"United States\", \"Mexico\", \"India\"]].T\n",
    "    ssy = ssc[[\"2018\"]]\n",
    "    ssy = ssy.reset_index()\n",
    "    fig, ax1 = plt.subplots(figsize=(20, 10), dpi=100)\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    tr = ssy.melt(id_vars='Country').rename(columns=str.title)\n",
    "    tr = tr.rename(columns={\"Variable\": \"Years\", \"Value\": f'{ylabel}'})\n",
    "    sns.barplot(x='Country', y=f'{ylabel}', hue='Years', data=tr, ax=ax1)\n",
    "    fig.suptitle(f'{title}', fontsize=30)\n",
    "    sns.despine(fig)\n",
    "\n",
    "print_piechart_sum(selected_countries_co2, \"Total Co2 emmision Between 1962-2020 per country\", \"Kilo Tone\")\n",
    "print(selected_countries_co2.sum(axis = 1))\n",
    "\n",
    "print_piechart_sum(selected_countries_me, \"Total Methan emision Between 1962-2020 per country\", \"Kilo Tones of CO2 equivalent\")\n",
    "print(selected_countries_me.sum(axis = 1))\n",
    "\n",
    "print_barplot_sum(forest, \"Forest Area by Country\",\"% of forest Area\")\n",
    "print(selected_countries_forest.sum(axis = 1))\n",
    "\n",
    "print_lineplot_sum(re, \"use of renewable energy  over time\", \"% of total final energy consumption\")\n",
    "print(selected_countries_re.sum(axis = 1))\n",
    "\n",
    "print_barplot_sum(pop, \"Population Growth per Country\",\"annual %\")\n",
    "print(selected_countries_pop.sum(axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments on the results of Country Characteristics\n",
    "\n",
    "To start answering our question, we choose to pick six which three of them (\"USA\", \"Mexico\", \"India\") has higher number of endangered species and the others lower once (\"Russia\",\"Vietnam\",\"Thailand\"), those countries are picked based on the findings above (Question 2).Therefore this approache is taken because of the lack of hardware resources, also for making the work more clean and informative which we don't need to plot 160+ countires data.\n",
    "\n",
    "As we see from the first sight in the plots it is obvious that higher number of endangered species are in countries with the most with Co2/methane emission also it shows a little bit of relationship between countries and their forest area, for the Renewable energy and methane there is no real correlation since higher endangered countries and the lower once show the same trend.\n",
    "\n",
    "## Conclusions\n",
    "\n",
    "In summary, we can conclude the three main Characteristics are \"Co2\",\"population\",\"forest\", therefore we will use them for more sophisticated analysis in Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4b - Prediction\n",
    "\n",
    "* Can these characteristics also predict trends in the number of endangered species?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_co2_raw = pd.read_csv(\"./data/country/CO2/API_EN.ATM.CO2E.KT_DS2_en_csv_v2_3470002.csv\", quotechar = '\"', skiprows=4)\n",
    "country_fst_raw = pd.read_csv(\"./data/country/Forest/API_AG.LND.FRST.ZS_DS2_en_csv_v2_3469441.csv\", quotechar = '\"', skiprows=4)\n",
    "country_pop_raw = pd.read_csv(\"./data/country/Population/API_SP.POP.GROW_DS2_en_csv_v2_3469469.csv\", quotechar = '\"', skiprows=4)\n",
    "country_me_raw = pd.read_csv(\"./data/country/methan/API_EN.ATM.METH.KT.CE_DS2_en_csv_v2_3471999.csv\", quotechar = '\"', skiprows=4)\n",
    "country_re_raw = pd.read_csv(\"./data/country/RE/API_EG.FEC.RNEW.ZS_DS2_en_csv_v2_3471475.csv\", quotechar = '\"', skiprows=4)\n",
    "\n",
    "def trs_data(df, value_name):\n",
    "    temp = (df\n",
    "                        .rename(columns={\"Country Code\": \"Code\"})\n",
    "                        .drop(['Indicator Code', 'Indicator Name', 'Country Name', '2020', '2019', 'Unnamed: 65'], axis=1)\n",
    "                        .melt(id_vars=['Code'],var_name='year', value_name=f'{value_name}'))\n",
    "    return temp\n",
    "\n",
    "\n",
    "df1 = trs_data(country_co2_raw, 'co2')\n",
    "df2 = trs_data(country_fst_raw, 'forest')\n",
    "df3 = trs_data(country_pop_raw, 'population')\n",
    "df4 = trs_data(country_me_raw, 'methan')\n",
    "df5 = trs_data(country_re_raw, 'renewable_energy')\n",
    "\n",
    "df = animalia_df.join(country_df, how='left')\n",
    "historical_df = historical_df.drop(['category', 'code'], axis=1)\n",
    "dfs = df.join(historical_df, how='left')\n",
    "dfs_min = dfs[['assessment_date', 'category', 'country', 'code_3', 'assess_year']]\n",
    "dfs_min= dfs_min.rename(columns={\"assess_year\": \"year\", \"code_3\": \"Code\"})\n",
    "\n",
    "merge = pd.merge(df1, df2, on=['Code', 'year'])\n",
    "merge = pd.merge(merge, df3, on=['Code', 'year'])\n",
    "merge = pd.merge(merge, df4, on=['Code', 'year'])\n",
    "merge_data = pd.merge(merge, df5, on=['Code', 'year'])\n",
    "merge_data[\"year\"] = merge_data[\"year\"].astype(str).astype(int)\n",
    "\n",
    "final = dfs_min.merge(merge_data, how='right', on=['Code', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = iucn_data.get_merged_historical_info().reset_index()\n",
    "cat = [\"Endangered\", \"Critically Endangered\", \"Vulnerable\"]\n",
    "label_mapping = {\"Critically Endangered\":\"CR\", \"Endangered\":\"EN\", \"Vulnerable\":\"VU\"}\n",
    "cat_cols = [\"indianred\", \"lightblue\", \"darkred\"]\n",
    "df = hist_df.query(f'category in {cat}')\n",
    "\n",
    "df['category'] = df['category'].map(label_mapping)\n",
    "\n",
    "df = df.groupby(['taxonid_iucn', 'category'])['year'].min().reset_index()\n",
    "df = df.groupby(['year', 'category']).count()\n",
    "df.columns = ['counts']\n",
    "\n",
    "df['no_csum'] = df.groupby(['category'])['counts'].cumsum()\n",
    "\n",
    "\n",
    "\n",
    "df_splt = df.reset_index()\n",
    "\n",
    "predict_df = df_splt.merge(final, how='right', on=['category', 'year'])\n",
    "corr = df_splt.merge(final, how='right', on=['category', 'year'])\n",
    "predict_df = predict_df.dropna(subset = ['co2', 'forest', 'population', 'methan', 'renewable_energy', 'category']).reset_index(drop=True)\n",
    "predict_df['assessment_date'] =  pd.to_datetime(predict_df['assessment_date'])\n",
    "predict_df = predict_df.rename(columns={\"assessment_date\": \"ds\", \"no_csum\": \"y\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMatrix = predict_df.corr()\n",
    "print (corrMatrix)\n",
    "sns.heatmap(corrMatrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split train test\n",
    "##\n",
    "\n",
    "f_train = predict_df.loc[predict_df[\"ds\"]<\"2010-01-01\"]\n",
    "f_test = predict_df.loc[predict_df[\"ds\"]>\"2010-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prediction without charectiristics\n",
    "##\n",
    "\n",
    "m = Prophet()\n",
    "\n",
    "m.fit((f_train))\n",
    "\n",
    "\n",
    "forcast = m.predict(f_test.drop(columns=\"y\"))\n",
    "plot_forecast_component(m, forcast, name='trend', uncertainty=True, figsize=(20, 6))\n",
    "plot_forecast_component(m, forcast, name='yearly', uncertainty=True, figsize=(20, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prediction with characteristics\n",
    "\n",
    "m = Prophet()\n",
    "\n",
    "m.add_regressor('co2')\n",
    "m.add_regressor('forest')\n",
    "m.add_regressor('population')\n",
    "\n",
    "\n",
    "m.fit((f_train))\n",
    "\n",
    "\n",
    "forcast = m.predict(f_test.drop(columns=\"y\"))\n",
    "plot_forecast_component(m, forcast, name='trend', uncertainty=True, figsize=(20, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "### Experiment 1: use only date values to predict future outcome\n",
    "\n",
    "By looking at the heat map, we quickly notice the huge correlation between years and the number of endangered species, based on that we trained our model using these values and we have got solid results, as it shows a solid prediction model, therefore when adding the country characteristics did not play any role for improving our model\n",
    "\n",
    "### Experiment 2: use date values and country characteristics to predict future outcome\n",
    "\n",
    "Here is the interesting part of the work, as we mentioned above those characteristics did not play any role in improving the model, we tried different approaches, in this case, we trained our model with only a few data this case (below 2010) and without added country characteristics (see Figure 1 above).\n",
    "\n",
    "The prediction was poor which makes sense as the model trained with fewer data, and also we can observe that the uncertainty is very high (light blue plot, which means the model was not very accurate about this prediction and it is not reliable at all.\n",
    "\n",
    "Now by adding additional data (country characteristics), and feeding our model with external data sources, our model improved dramatically, even the uncertainty rate has been improved, therefore we see a solid prediction\n",
    "\n",
    "## Findings\n",
    "\n",
    "In conclusion, the additional data added to the model improved the prediction but we cannot say these characteristics are the main role of the endangered species, obviously, there are more aspects to this but in summary, the idea behind this is to try and build a model with fewer data and feed it with external resources, in this case, our 3 characteristics that are not highly correlated to the target value and try to build a nice model out of it which in this case worked very well, but again only in this case.\n",
    "\n",
    "## Lessons learned\n",
    "\n",
    "Getting data or in other words, getting *useful* data is not easy as it seems. The country-wise data had a lot of missing values, and some data were not even collected or labeled properly.\n",
    "\n",
    "Merging and querying the data to find the answer was not easy especially if gathering data from multiple sources, as it will cause some inconsistencies and maybe inbalance or outliers. In this case, merging data from IUCN and World Bank caused a lot of issues that needed a lot of time and effort to handle.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
